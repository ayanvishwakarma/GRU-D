{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7439409,"sourceType":"datasetVersion","datasetId":4287453}],"dockerImageVersionId":30350,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Environment Setup in Kaggle\n# Create New Conda Environment and Use Conda Channel \n!conda create -n newCondaEnvironment -c cctbx202208 -y &> /dev/null\n!source /opt/conda/bin/activate newCondaEnvironment && conda install -c cctbx202208 python=3.6 -y &> /dev/null\n!/opt/conda/envs/newCondaEnvironment/bin/python --version\n!sudo rm /opt/conda/bin/python\n!sudo ln -sf /opt/conda/envs/newCondaEnvironment/bin/python /opt/conda/bin/python\n!sudo rm /opt/conda/bin/python\n!sudo ln -sf /opt/conda/envs/newCondaEnvironment/bin/python /opt/conda/bin/python\n!sudo rm /opt/conda/bin/python\n!sudo ln -s /opt/conda/envs/newCondaEnvironment/bin/python /opt/conda/bin/python\n!python --version","metadata":{"execution":{"iopub.status.busy":"2024-02-07T19:19:32.748283Z","iopub.execute_input":"2024-02-07T19:19:32.750134Z","iopub.status.idle":"2024-02-07T19:21:20.231153Z","shell.execute_reply.started":"2024-02-07T19:19:32.749980Z","shell.execute_reply":"2024-02-07T19:21:20.229735Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Python 3.6.15\nPython 3.6.15\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install jupyter &> /dev/null","metadata":{"execution":{"iopub.status.busy":"2024-02-07T19:21:20.234073Z","iopub.execute_input":"2024-02-07T19:21:20.234536Z","iopub.status.idle":"2024-02-07T19:21:36.451993Z","shell.execute_reply.started":"2024-02-07T19:21:20.234492Z","shell.execute_reply":"2024-02-07T19:21:36.450315Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import git\nimport os \nimport shutil\n\nos.chdir('/kaggle/working/')\n\nGITHUB_ACCESS_TOKEN = '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'\n\nif os.path.exists('GRU-D'):\n    shutil.rmtree('/kaggle/working/GRU-D')\n\ngit.Repo.clone_from(f'https://{GITHUB_ACCESS_TOKEN}@github.com/ayanvishwakarma/GRU-D.git', 'GRU-D')\n\nos.chdir('/kaggle/working/GRU-D')\nprint('Present working directory:',os.getcwd())\n\n!pip install -r requirements.txt --use-deprecated=legacy-resolver &> /dev/null\n\nif not os.path.exists('data/p19'):\n    os.mkdir('data/p19')\n    \nimport sys\nsys.path.append('/kaggle/working/GRU-D/Code')","metadata":{"execution":{"iopub.status.busy":"2024-02-07T20:37:00.143618Z","iopub.execute_input":"2024-02-07T20:37:00.144143Z","iopub.status.idle":"2024-02-07T20:37:14.697639Z","shell.execute_reply.started":"2024-02-07T20:37:00.144105Z","shell.execute_reply":"2024-02-07T20:37:14.695808Z"},"trusted":true},"execution_count":81,"outputs":[{"name":"stdout","text":"Present working directory: /kaggle/working/GRU-D\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nimport os\nimport numpy as np\nimport random\n\ndef seed_everything(seed):\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    random.seed(seed)\n    tf.random.set_random_seed(seed)\n    np.random.seed(seed)\n    \ndef set_global_determinism(seed):\n    seed_everything(seed=seed)\n\n    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n    \nset_global_determinism(2024)","metadata":{"execution":{"iopub.status.busy":"2024-02-07T19:22:30.655566Z","iopub.execute_input":"2024-02-07T19:22:30.656000Z","iopub.status.idle":"2024-02-07T19:22:31.862497Z","shell.execute_reply.started":"2024-02-07T19:22:30.655955Z","shell.execute_reply":"2024-02-07T19:22:31.861327Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\n\nimport git\nimport os \nimport shutil\n\nos.chdir('/kaggle/working/')\n\nGITHUB_ACCESS_TOKEN = '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'\n\nif os.path.exists('SLAN'):\n    shutil.rmtree('/kaggle/working/SLAN')\n\ngit.Repo.clone_from(f'https://{GITHUB_ACCESS_TOKEN}@github.com/ayanvishwakarma/SLAN.git', 'SLAN')\n\nos.chdir('/kaggle/working/SLAN')\nprint('Present working directory:',os.getcwd())\n\n!pip install -r requirements.txt --use-deprecated=legacy-resolver &> /dev/null\n\nimport sys\nsys.path.append('/kaggle/working/SLAN/Code')\n\nfrom data import P19data\ntrain_dataset = P19data('/kaggle/input/mimic-text/P19/P19/', 'train', 'cpu')\nval_dataset = P19data('/kaggle/input/mimic-text/P19/P19/', 'val', 'cpu')\ntest_dataset = P19data('/kaggle/input/mimic-text/P19/P19/', 'test', 'cpu')\n\ndata = {'timestamp': [((x['t'] - x['t'][0]) * 60 * 60).numpy() for dataset in [train_dataset, val_dataset, test_dataset] for x in dataset],\n    'masking': [np.logical_not(np.isnan(x['sensor_values'])).numpy() for dataset in [train_dataset, val_dataset, test_dataset] for x in dataset],\n    'input': [x['sensor_values'].numpy() for dataset in [train_dataset, val_dataset, test_dataset] for x in dataset],\n    'label_mortality': [x['y'].numpy()[:, np.newaxis] for dataset in [train_dataset, val_dataset, test_dataset] for x in dataset]}\n\nfold_info = {'fold_mortality': [[np.arange(len(train_dataset)), len(train_dataset) + np.arange(len(val_dataset)), \n                                len(train_dataset) + len(val_dataset) + np.arange(len(test_dataset))]], \n    'mean_mortality': [train_dataset.loaded_stat[x]['mean'] for x in train_dataset.loaded_stat],\n    'std_mortality': [train_dataset.loaded_stat[x]['std'] for x in train_dataset.loaded_stat]}\nfold_info['mean_mortality'] = [np.array([x if not x is None else np.nan for x in fold_info['mean_mortality']]), \n                              np.full(len(fold_info['mean_mortality']), fill_value=np.nan),\n                              np.full(len(fold_info['mean_mortality']), fill_value=np.nan)]\nfold_info['std_mortality'] = [np.array([x if not x is None else np.nan for x in fold_info['std_mortality']]),\n                             np.full(len(fold_info['std_mortality']), fill_value=np.nan),\n                             np.full(len(fold_info['std_mortality']), fill_value=np.nan)]\n\ndata = {key: np.array(value, dtype='O') for key, value in data.items()}\nfold_info = {key: np.array(value, dtype='O') for key, value in fold_info.items()}\n\nnp.savez_compressed(os.path.join('/kaggle/working/GRU-D/data/p19/', 'data.npz'), **data)\nnp.savez_compressed(os.path.join('/kaggle/working/GRU-D/data/p19/', 'fold.npz'), **fold_info)","metadata":{"execution":{"iopub.status.busy":"2024-02-07T19:22:31.864067Z","iopub.execute_input":"2024-02-07T19:22:31.865671Z","iopub.status.idle":"2024-02-07T19:25:40.288188Z","shell.execute_reply.started":"2024-02-07T19:22:31.865612Z","shell.execute_reply":"2024-02-07T19:25:40.286677Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Present working directory: /kaggle/working/SLAN\ntrain loaded , num of instances: 25813\nval loaded , num of instances: 6454\ntest loaded , num of instances: 8066\nCPU times: user 2min 55s, sys: 1.84 s, total: 2min 56s\nWall time: 3min 8s\n","output_type":"stream"}]},{"cell_type":"code","source":"from __future__ import absolute_import, division, print_function\n\nos.chdir('/kaggle/working/GRU-D')\nprint('Present working directory:',os.getcwd())\n\nimport argparse\nfrom datetime import datetime\nimport numpy as np\nimport os\n\nfrom keras import backend as K\nfrom keras.callbacks import EarlyStopping, TensorBoard\nimport numpy as np\nfrom sklearn.metrics import roc_auc_score, average_precision_score\n\nfrom data_handler import DataHandler\nfrom models import create_grud_model, load_grud_model\nfrom nn_utils.callbacks import ModelCheckpointwithBestWeights\n\nfrom utility_score_calculation import physionet2019_utility\nfrom sklearn.metrics import balanced_accuracy_score","metadata":{"execution":{"iopub.status.busy":"2024-02-07T19:56:52.012972Z","iopub.execute_input":"2024-02-07T19:56:52.013521Z","iopub.status.idle":"2024-02-07T19:56:52.030010Z","shell.execute_reply.started":"2024-02-07T19:56:52.013480Z","shell.execute_reply":"2024-02-07T19:56:52.028216Z"},"trusted":true},"execution_count":70,"outputs":[{"name":"stdout","text":"Present working directory: /kaggle/working/GRU-D\n","output_type":"stream"}]},{"cell_type":"code","source":"# set GPU usage for tensorflow backend\nif K.backend() == 'tensorflow':\n    import tensorflow as tf\n    config = tf.ConfigProto()\n    config.gpu_options.per_process_gpu_memory_fraction = .1\n    config.gpu_options.allow_growth = True\n    config.intra_op_parallelism_threads = 1\n    config.inter_op_parallelism_threads = 1\n    K.set_session(tf.Session(config=config))","metadata":{"execution":{"iopub.status.busy":"2024-02-07T19:25:40.726312Z","iopub.execute_input":"2024-02-07T19:25:40.727279Z","iopub.status.idle":"2024-02-07T19:25:40.742652Z","shell.execute_reply.started":"2024-02-07T19:25:40.727228Z","shell.execute_reply":"2024-02-07T19:25:40.741464Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"arg_parser = argparse.ArgumentParser()\narg_parser.add_argument('--working_path', default='.')\n\n## data\narg_parser.add_argument('dataset_name', default='mimic3',\n                        help='The data files should be saved in [working_path]/data/[dataset_name] directory.')\narg_parser.add_argument('label_name', default='mortality')\narg_parser.add_argument('--max_timesteps', type=int, default=350, \n                        help='Time series of at most # time steps are used. Default: 200.')\narg_parser.add_argument('--max_timestamp', type=int, default=48*60*60,\n                        help='Time series of at most # seconds are used. Default: 48 (hours).')\n\n## model\narg_parser.add_argument('--recurrent_dim', type=lambda x: x and [int(xx) for xx in x.split(',')] or [], default='64')\narg_parser.add_argument('--hidden_dim', type=lambda x: x and [int(xx) for xx in x.split(',')] or [], default='64')\narg_parser.add_argument('--model', default='GRUD', choices=['GRUD', 'GRUforward', 'GRU0', 'GRUsimple'])\narg_parser.add_argument('--use_bidirectional_rnn', default=False)\n                           \n## training\narg_parser.add_argument('--pretrained_model_file', default=None,\n                        help='If pre-trained model is provided, training will be skipped.') # e.g., [model_name]_[i_fold].h5\narg_parser.add_argument('--epochs', type=int, default=100)\narg_parser.add_argument('--early_stopping_patience', type=int, default=10)\narg_parser.add_argument('--batch_size', type=int, default=32)\n\n\n## set the actual arguments if running in notebook\nif not (__name__ == '__main__' and '__file__' in globals()):\n    ARGS = arg_parser.parse_args([\n        'p19',\n        'mortality',\n        '--model', 'GRUD',\n        '--hidden_dim', '',\n        '--epochs', '100',\n        '--recurrent_dim', '64, 1'\n    ])\nelse:\n    ARGS = arg_parser.parse_args()\n\nprint('Arguments:', ARGS)","metadata":{"execution":{"iopub.status.busy":"2024-02-07T20:19:18.667173Z","iopub.execute_input":"2024-02-07T20:19:18.667716Z","iopub.status.idle":"2024-02-07T20:19:18.689971Z","shell.execute_reply.started":"2024-02-07T20:19:18.667679Z","shell.execute_reply":"2024-02-07T20:19:18.688393Z"},"trusted":true},"execution_count":77,"outputs":[{"name":"stdout","text":"Arguments: Namespace(batch_size=32, dataset_name='p19', early_stopping_patience=10, epochs=1, hidden_dim=[], label_name='mortality', max_timestamp=172800, max_timesteps=350, model='GRUD', pretrained_model_file=None, recurrent_dim=[64, 1], use_bidirectional_rnn=False, working_path='.')\n","output_type":"stream"}]},{"cell_type":"code","source":"dataset = DataHandler(\n    data_path=os.path.join('/kaggle/working/GRU-D', 'data', ARGS.dataset_name), \n    label_name=ARGS.label_name, \n    max_steps=ARGS.max_timesteps,\n    max_timestamp=ARGS.max_timestamp\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-07T20:19:20.941029Z","iopub.execute_input":"2024-02-07T20:19:20.941550Z","iopub.status.idle":"2024-02-07T20:19:26.070424Z","shell.execute_reply.started":"2024-02-07T20:19:20.941512Z","shell.execute_reply":"2024-02-07T20:19:26.068910Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"def weighted_bce(y_true, y_pred):\n    y_true, y_pred = tf.reshape(y_true, shape=(-1,)), tf.reshape(y_pred, shape=(-1,))\n    valid_inds = tf.where(tf.logical_not(tf.equal(y_true, -1)))\n    y_true = tf.gather(y_true, valid_inds)\n    y_pred = tf.gather(y_pred, valid_inds)\n    weights = y_true * 26.9973 + (1 - y_true) * 0.5094\n    bce = K.binary_crossentropy(y_true, y_pred)\n    weighted_bce = K.mean(bce * weights)\n    return weighted_bce","metadata":{"execution":{"iopub.status.busy":"2024-02-07T20:19:26.072842Z","iopub.execute_input":"2024-02-07T20:19:26.073410Z","iopub.status.idle":"2024-02-07T20:19:26.082137Z","shell.execute_reply.started":"2024-02-07T20:19:26.073350Z","shell.execute_reply":"2024-02-07T20:19:26.080615Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"# k-fold cross-validation\npred_y_list_all = []\nauc_score_list_all = []\n\ntimestamp = datetime.now().strftime('%Y%m%d_%H%M%S_%f')\nprint('Timestamp: {}'.format(timestamp))\n\nfor i_fold in range(dataset.folds):\n    print('{}-th fold...'.format(i_fold))\n\n    # Load or train the model.\n    if ARGS.pretrained_model_file is not None:\n        model = load_grud_model(os.path.join(ARGS.working_path, \n                                             ARGS.pretrained_model_file.format(i_fold=i_fold)))\n    else:\n        model = create_grud_model(input_dim=dataset.input_dim,\n                                  output_dim=dataset.output_dim,\n                                  output_activation=dataset.output_activation,\n                                  recurrent_dim=ARGS.recurrent_dim,\n                                  hidden_dim=ARGS.hidden_dim,\n                                  predefined_model=ARGS.model,\n                                  use_bidirectional_rnn=ARGS.use_bidirectional_rnn,\n                                  return_sequences_grud=True\n                                 )\n        if i_fold == 0:\n            model.summary()\n        model.compile(optimizer='adam', loss=weighted_bce) #dataset.loss_function)\n        model.fit_generator(\n            generator=dataset.training_generator(i_fold, batch_size=ARGS.batch_size, \n                                                return_sequences_grud=True),\n            steps_per_epoch=dataset.training_steps(i_fold, batch_size=ARGS.batch_size),\n            epochs=ARGS.epochs,\n            verbose=1,\n            validation_data=dataset.validation_generator(i_fold, batch_size=ARGS.batch_size,\n                                                        return_sequences_grud=True),\n            validation_steps=dataset.validation_steps(i_fold, batch_size=ARGS.batch_size),\n            callbacks=[\n                EarlyStopping(patience=ARGS.early_stopping_patience),\n                ModelCheckpointwithBestWeights(\n                    file_dir=os.path.join(ARGS.working_path, 'model', timestamp + '_' + str(i_fold))\n                ),\n                TensorBoard(\n                    log_dir=os.path.join(ARGS.working_path, 'tb_logs', timestamp + '_' + str(i_fold))\n                )\n            ]\n            )\n        model.save(os.path.join(ARGS.working_path, 'model', \n                                timestamp + '_' + str(i_fold), 'model.h5'))\n\n    # Evaluate the model\n    true_y_list = [\n        dataset.training_y(i_fold), dataset.validation_y(i_fold), dataset.testing_y(i_fold)\n    ]\n    pred_y_list = [\n        model.predict_generator(dataset.training_generator_x(i_fold, batch_size=ARGS.batch_size,\n                                                            return_sequences_grud=True),\n                                steps=dataset.training_steps(i_fold, batch_size=ARGS.batch_size)),\n        model.predict_generator(dataset.validation_generator_x(i_fold, batch_size=ARGS.batch_size,\n                                                              return_sequences_grud=True),\n                                steps=dataset.validation_steps(i_fold, batch_size=ARGS.batch_size)),\n        model.predict_generator(dataset.testing_generator_x(i_fold, batch_size=ARGS.batch_size,\n                                                           return_sequences_grud=True),\n                                steps=dataset.testing_steps(i_fold, batch_size=ARGS.batch_size)),\n    ]\n    \n    pred_y_list = [[i_pred[:len(i_true)] for i_pred, i_true in zip(pred, true)] for pred, true in zip(pred_y_list, true_y_list)]\n    true_y_list = [np.concatenate(true).ravel() for true in true_y_list]\n    pred_y_list = [np.concatenate(pred).ravel() for pred in pred_y_list]\n    \n    auc_score_list = [roc_auc_score(ty, py, average='macro') for ty, py in zip(true_y_list, pred_y_list)]\n    aurpc_score_list= [average_precision_score(ty, py) for ty, py in zip(true_y_list, pred_y_list)]\n    bacc_score_list = [balanced_accuracy_score(ty, py > 0.5) for ty, py in zip(true_y_list, pred_y_list)]\n    unorm_score_list = [physionet2019_utility(ty, np.stack(zip(1 - py, py))) for ty, py in zip(true_y_list, pred_y_list)]\n    \n    print('AUC score of this fold: {}'.format(auc_score_list))\n    print('AUPRC score of this fold: {}'.format(aurpc_score_list))\n    print('BACC score of this fold: {}'.format(bacc_score_list))\n    print('UNORM score of this fold: {}'.format(unorm_score_list))\n    pred_y_list_all.append(pred_y_list)\n    auc_score_list_all.append(auc_score_list)\n\nprint('Finished!', '='*20)\nauc_score_list_all = np.stack(auc_score_list_all, axis=0)\nprint('Mean AUC score: {}; Std AUC score: {}'.format(\n    np.mean(auc_score_list_all, axis=0),\n    np.std(auc_score_list_all, axis=0)))\n\nresult_path = os.path.join(ARGS.working_path, 'results', timestamp)\nif not os.path.exists(result_path):\n    os.makedirs(result_path)\nnp.savez_compressed(os.path.join(result_path, 'predictions.npz'),\n                    pred_y_list_all=pred_y_list_all)\nnp.savez_compressed(os.path.join(result_path, 'auroc_score.npz'),\n                    auc_score_list_all=auc_score_list_all)","metadata":{"execution":{"iopub.status.busy":"2024-02-07T20:19:26.084508Z","iopub.execute_input":"2024-02-07T20:19:26.084986Z","iopub.status.idle":"2024-02-07T20:35:37.434096Z","shell.execute_reply.started":"2024-02-07T20:19:26.084907Z","shell.execute_reply":"2024-02-07T20:35:37.432748Z"},"trusted":true},"execution_count":80,"outputs":[{"name":"stdout","text":"Timestamp: 20240207_201926_114755\n0-th fold...\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_13 (InputLayer)           (None, None, 34)     0                                            \n__________________________________________________________________________________________________\ninput_14 (InputLayer)           (None, None, 34)     0                                            \n__________________________________________________________________________________________________\ninput_15 (InputLayer)           (None, None, 1)      0                                            \n__________________________________________________________________________________________________\nexternal_masking_9 (ExternalMas (None, None, 34)     0           input_13[0][0]                   \n                                                                 input_14[0][0]                   \n__________________________________________________________________________________________________\nmasking_5 (Masking)             (None, None, 34)     0           input_14[0][0]                   \n__________________________________________________________________________________________________\nexternal_masking_10 (ExternalMa (None, None, 1)      0           input_15[0][0]                   \n                                                                 input_14[0][0]                   \n__________________________________________________________________________________________________\ngrud_5 (GRUD)                   (None, None, 64)     27844       external_masking_9[0][0]         \n                                                                 masking_5[0][0]                  \n                                                                 external_masking_10[0][0]        \n__________________________________________________________________________________________________\ndropout_5 (Dropout)             (None, None, 64)     0           grud_5[0][0]                     \n__________________________________________________________________________________________________\ndense_5 (Dense)                 (None, None, 1)      65          dropout_5[0][0]                  \n==================================================================================================\nTotal params: 27,909\nTrainable params: 27,909\nNon-trainable params: 0\n__________________________________________________________________________________________________\nEpoch 1/1\n807/807 [==============================] - 429s 531ms/step - loss: 0.6687 - val_loss: 0.6294.........................................................................................................................................................................................\n.........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3552: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n  exec(code_obj, self.user_global_ns, self.user_ns)\n","output_type":"stream"},{"name":"stdout","text":"AUC score of this fold: [0.7109743178704325, 0.711703215224365, 0.687338001578342]\nAUPRC score of this fold: [0.04432392703498352, 0.04134872098658058, 0.036148219926611505]\nBACC score of this fold: [0.6554367910119132, 0.6589663436542249, 0.6340521343111208]\nFinished! ====================\nMean AUC score: [0.71097432 0.71170322 0.687338  ]; Std AUC score: [0. 0. 0.]\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/numpy/lib/npyio.py:719: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n  val = np.asanyarray(val)\n","output_type":"stream"}]}]}